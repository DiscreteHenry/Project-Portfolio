{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb4d0b4b",
   "metadata": {},
   "source": [
    "<center><h1>CTA Prediction Tool <center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45e6d4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import torch\n",
    "import nibabel as nib\n",
    "import cv2\n",
    "import pydicom\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import ipywidgets as widgets\n",
    "from ipyfilechooser import FileChooser\n",
    "from IPython.display import display, HTML, clear_output\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# --- Global Stop Flag ---\n",
    "stop_flag = {'terminate': False}\n",
    "last_processed = {'scan': None}\n",
    "\n",
    "# --- ResNet18 Model Definition ---\n",
    "class SliceCNN(nn.Module):\n",
    "    def __init__(self, feature_dim=128):\n",
    "        super(SliceCNN, self).__init__()\n",
    "        base_model = models.resnet18(pretrained=False)\n",
    "        base_model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.backbone = nn.Sequential(*list(base_model.children())[:-1])\n",
    "        self.fc = nn.Linear(512, feature_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "class CTAQuality2D(nn.Module):\n",
    "    def __init__(self, feature_dim=128):\n",
    "        super(CTAQuality2D, self).__init__()\n",
    "        self.slice_cnn = SliceCNN(feature_dim)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(feature_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, S, C, H, W = x.shape\n",
    "        x = x.view(B * S, C, H, W)\n",
    "        feats = self.slice_cnn(x)\n",
    "        feats = feats.view(B, S, -1)\n",
    "        pooled = feats.mean(dim=1)\n",
    "        out = self.classifier(pooled)\n",
    "        return torch.sigmoid(out.squeeze(1))\n",
    "\n",
    "# --- Preprocessing ---\n",
    "def load_scan(file_path):\n",
    "    file_path = str(pathlib.Path(file_path))\n",
    "    if file_path.endswith('.nii') or file_path.endswith('.nii.gz'):\n",
    "        img = nib.load(file_path)\n",
    "        return img.get_fdata()\n",
    "    elif os.path.isdir(file_path):\n",
    "        dicom_files = [f for f in os.listdir(file_path) if f.endswith('.dcm')]\n",
    "        if not dicom_files:\n",
    "            raise FileNotFoundError(f\"No DICOM files in {file_path}\")\n",
    "        slices = [pydicom.dcmread(os.path.join(file_path, f)) for f in dicom_files]\n",
    "        slices.sort(key=lambda x: float(x.ImagePositionPatient[2]))\n",
    "        volume = np.stack([s.pixel_array for s in slices], axis=-1)\n",
    "        return volume\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type\")\n",
    "\n",
    "def normalize_volume(volume):\n",
    "    volume = volume.astype(np.float32)\n",
    "    volume -= np.min(volume)\n",
    "    volume /= np.max(volume)\n",
    "    return volume\n",
    "\n",
    "def extract_12_slices(volume):\n",
    "    z_len = volume.shape[2]\n",
    "    axial_indices = np.linspace(0, z_len - 1, 10, dtype=int)\n",
    "    axial_slices = [volume[:, :, idx] for idx in axial_indices]\n",
    "    coronal = volume[:, volume.shape[1] // 2, :]\n",
    "    sagittal = volume[volume.shape[0] // 2, :, :]\n",
    "    return axial_slices + [coronal, sagittal]\n",
    "\n",
    "def preprocess_scan(path, target_size=(224, 224)):\n",
    "    volume = load_scan(path)\n",
    "    volume = normalize_volume(volume)\n",
    "    slices = extract_12_slices(volume)\n",
    "    resized = [cv2.resize(s, target_size, interpolation=cv2.INTER_AREA) for s in slices]\n",
    "    return np.stack(resized, axis=0)\n",
    "\n",
    "def predict_single(model, path, device, threshold=0.5):\n",
    "    try:\n",
    "        slices = preprocess_scan(path)\n",
    "        print(\"Input stats:\")\n",
    "        print(f\"  Min: {np.min(slices):.4f}, Max: {np.max(slices):.4f}, Std: {np.std(slices):.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to preprocess {path}: {e}\")\n",
    "        return None  # Or return a default value\n",
    "\n",
    "    slices = torch.tensor(slices).unsqueeze(1).unsqueeze(0).float().to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logit = model(slices).item()\n",
    "        prob = torch.sigmoid(torch.tensor(logit)).item()\n",
    "        pred = 1 if prob > threshold else 0\n",
    "\n",
    "    print(f\"Scan: {path}\")\n",
    "    print(f\"  Logit: {logit:.2f}\")\n",
    "    print(f\"  Sigmoid Probability: {prob:.4f}\")\n",
    "    print(f\"  Predicted Label: {pred} (Threshold: {threshold})\")\n",
    "    return round(prob, 4)\n",
    "\n",
    "def colorize_score(val):\n",
    "    if pd.isnull(val):\n",
    "        return 'background-color: lightgray'\n",
    "    elif val >= 0.7:\n",
    "        return 'background-color: lightgreen'\n",
    "    elif val >= 0.4:\n",
    "        return 'background-color: khaki'\n",
    "    else:\n",
    "        return 'background-color: lightcoral'\n",
    "\n",
    "def clear_done_cache():\n",
    "    if os.path.exists(\".predictions\"):\n",
    "        shutil.rmtree(\".predictions\")\n",
    "        print(\"Cleared .predictions cache.\")\n",
    "    else:\n",
    "        print(\"No .predictions cache to clear.\")\n",
    "\n",
    "# --- Restore sync prediction function ---\n",
    "def predict_batch_recursive(model_path, root_dir):\n",
    "    results = []\n",
    "    log_lines = []\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = CTAQuality2D()\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    scan_targets = []\n",
    "    for dirpath, _, filenames in os.walk(root_dir):\n",
    "        nifti_files = [f for f in filenames if f.endswith('.nii') or f.endswith('.nii.gz')]\n",
    "        for f in nifti_files:\n",
    "            rel_path = os.path.relpath(os.path.join(dirpath, f), root_dir)\n",
    "            if not os.path.exists(f\".predictions/{rel_path}.done\"):\n",
    "                scan_targets.append((os.path.join(dirpath, f), 'NIfTI'))\n",
    "\n",
    "        dicom_files = [f for f in filenames if f.endswith('.dcm')]\n",
    "        if dicom_files:\n",
    "            rel_path = os.path.relpath(dirpath, root_dir)\n",
    "            if not os.path.exists(f\".predictions/{rel_path}.done\"):\n",
    "                scan_targets.append((dirpath, 'DICOM'))\n",
    "\n",
    "    os.makedirs(\".predictions\", exist_ok=True)\n",
    "\n",
    "    for scan_path, scan_type in tqdm(scan_targets, desc=\"Processing Scans\"):\n",
    "        if stop_flag['terminate']:\n",
    "            tqdm.write(\"Termination requested. Stopping early.\")\n",
    "            break\n",
    "        last_processed['scan'] = scan_path\n",
    "        tqdm.write(f\"Processing: {scan_path}\")\n",
    "        try:\n",
    "            score = predict_single(model, scan_path, device)\n",
    "            results.append({\n",
    "                \"scan\": os.path.relpath(scan_path, root_dir),\n",
    "                \"type\": scan_type,\n",
    "                \"quality_score\": score\n",
    "            })\n",
    "            done_flag = f\".predictions/{os.path.relpath(scan_path, root_dir)}.done\"\n",
    "            os.makedirs(os.path.dirname(done_flag), exist_ok=True)\n",
    "            with open(done_flag, 'w') as f:\n",
    "                f.write(\"done\")\n",
    "            log_lines.append(f\"SUCCESS: {scan_path} -> {score:.2f}\")\n",
    "        except Exception as e:\n",
    "            results.append({\n",
    "                \"scan\": os.path.relpath(scan_path, root_dir),\n",
    "                \"type\": scan_type,\n",
    "                \"quality_score\": None,\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "            log_lines.append(f\"ERROR: {scan_path} -> {e}\")\n",
    "\n",
    "    with open(\"cta_prediction_log.txt\", \"w\", encoding=\"utf-8\") as log:\n",
    "        for line in log_lines:\n",
    "            log.write(line + \"\\n\")\n",
    "\n",
    "    print(f\"Finished. Last processed scan: {last_processed['scan']}\")\n",
    "    print(f\"Total processed: {len(results)}\")\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38d67e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f747b150ea54656aa9606f4e8830d0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FileChooser(path='C:\\Users\\HenryLi\\Desktop\\Python Projects\\CTA Scan Binary Classifier', filenamâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- UI Block ---\n",
    "def stop_prediction(_):\n",
    "    stop_flag['terminate'] = True\n",
    "# (same as before except run_prediction becomes synchronous)\n",
    "def run_prediction(_):\n",
    "    stop_flag['terminate'] = False\n",
    "    output.clear_output()\n",
    "    with output:\n",
    "        model_path = model_chooser.selected\n",
    "        scan_path = scan_chooser.selected\n",
    "\n",
    "        if not model_path or not scan_path:\n",
    "            print(\"Please select both a model and a scan input.\")\n",
    "            return\n",
    "\n",
    "        if os.path.isfile(scan_path) and (scan_path.endswith('.nii') or scan_path.endswith('.nii.gz')):\n",
    "            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            model = CTAQuality2D()\n",
    "            model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "            model.to(device)\n",
    "            model.eval()\n",
    "            score = predict_single(model, scan_path, device)\n",
    "            print(f\"Predicted quality score for {scan_path} -> {score:.2f}\")\n",
    "\n",
    "        elif os.path.isdir(scan_path):\n",
    "            df = predict_batch_recursive(model_path, scan_path)\n",
    "            if 'quality_score' in df.columns:\n",
    "                styled_df = df.style.map(colorize_score, subset=['quality_score'])\n",
    "                display(HTML(styled_df.to_html()))\n",
    "            else:\n",
    "                print(\"No valid results to display.\")\n",
    "                display(df)\n",
    "\n",
    "            save_btn = widgets.Button(description=\"Save CSV\")\n",
    "            zip_btn = widgets.Button(description=\"Download Results as ZIP\")\n",
    "\n",
    "            def save_callback(b):\n",
    "                try:\n",
    "                    df.to_csv(\"cta_quality_results.csv\", index=False)\n",
    "                    print(\"Saved to cta_quality_results.csv\")\n",
    "                except Exception as e:\n",
    "                    print(\"Failed to save CSV:\", e)\n",
    "\n",
    "            def zip_callback(b):\n",
    "                try:\n",
    "                    with zipfile.ZipFile(\"cta_results_bundle.zip\", 'w') as zipf:\n",
    "                        zipf.write(\"cta_quality_results.csv\")\n",
    "                        zipf.write(\"cta_prediction_log.txt\")\n",
    "                    print(\"Created cta_results_bundle.zip\")\n",
    "                except Exception as e:\n",
    "                    print(\"Failed to create ZIP:\", e)\n",
    "\n",
    "            save_btn.on_click(save_callback)\n",
    "            zip_btn.on_click(zip_callback)\n",
    "            display(widgets.HBox([save_btn, zip_btn]))\n",
    "\n",
    "        else:\n",
    "            print(\"Unsupported input.\")\n",
    "\n",
    "model_chooser = FileChooser(os.getcwd(), title=\"Select Model (.pt)\", filter_pattern=\"*.pt\")\n",
    "scan_chooser = FileChooser(os.getcwd(), title=\"Select scan file or folder\")\n",
    "run_btn = widgets.Button(description=\"Run Prediction\")\n",
    "stop_btn = widgets.Button(description=\"Stop\")\n",
    "clear_cache_btn = widgets.Button(description=\"Clear .done Cache\", button_style='warning')\n",
    "output = widgets.Output()\n",
    "\n",
    "clear_cache_btn.on_click(lambda b: clear_done_cache())\n",
    "stop_btn.on_click(stop_prediction)\n",
    "run_btn.on_click(run_prediction)\n",
    "\n",
    "display(widgets.VBox([\n",
    "    model_chooser,\n",
    "    scan_chooser,\n",
    "    widgets.HBox([run_btn, stop_btn, clear_cache_btn]),\n",
    "    output\n",
    "]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
